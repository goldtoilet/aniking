import os
import io
import base64
import re
from concurrent.futures import ThreadPoolExecutor, as_completed

import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv

from PIL import Image
import numpy as np  # â† ì¶”ê°€

# imageioê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ í™˜ê²½ì—ì„œë„ ì•±ì´ ì£½ì§€ ì•Šê²Œ ì˜ˆì™¸ ì²˜ë¦¬
try:
    import imageio.v2 as imageio
except ImportError:
    imageio = None

# =========================
# .env ë¡œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ë¡œì»¬ ê°œë°œìš©)
# =========================
load_dotenv()

# =========================
# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • & ìŠ¤íƒ€ì¼
# =========================
st.set_page_config(
    page_title="imageking",
    page_icon="ğŸ¬",
    layout="wide",
)

st.markdown(
    """
    <style>
    textarea {
        font-size: 0.9rem !important;
        line-height: 1.4 !important;
    }
    .main-title {
        font-size: 2.3rem;
        font-weight: 800;
        margin-bottom: 0.2rem;
    }
    .main-subtitle {
        font-size: 0.95rem;
        color: #555;
        margin-bottom: 1.5rem;
    }
    .logo-badge {
        display: inline-flex;
        align-items: center;
        gap: 0.35rem;
        padding: 0.25rem 0.6rem;
        border-radius: 999px;
        background: #F3F4FF;
        color: #444;
        font-size: 0.8rem;
        margin-bottom: 0.5rem;
    }
    .logo-badge span.emoji {
        font-size: 1rem;
    }
    /* ê²°ê³¼ í…Œì´ë¸”ìš© ìŠ¤í¬ë¡¤ ë°•ìŠ¤ */
    .results-container {
        max-height: 600px;
        overflow-y: auto;
        padding-right: 8px;
        border-radius: 8px;
        border: 1px solid #eee;
        background-color: #fafafa;
    }
    /* í…Œì´ë¸” ì•ˆ í…ìŠ¤íŠ¸ í¬ê¸° ì¤„ì´ê¸° */
    .small-text-cell {
        font-size: 0.8rem;
        line-height: 1.3;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# =========================
# í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
# =========================
def get_env(key: str, default: str = "") -> str:
    value = os.getenv(key)
    return value if value is not None else default


GPT_API_KEY = get_env("GPT_API_KEY", "")

if not GPT_API_KEY:
    st.error("âŒ GPT_API_KEY ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=GPT_API_KEY)

# =========================
# ì´ë¯¸ì§€ / ì˜ìƒ ëª¨ë¸ í”„ë¦¬ì…‹
# =========================
IMAGE_MODELS = {
    "OpenAI gpt-image-1": "gpt-image-1",
}

VIDEO_MODELS = {
    "ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ â†’ MP4 (ë¡œì»¬ í•©ì„±)": "local_sequence_mp4",
}

# =========================
# ì„¸ì…˜ ìƒíƒœ ê¸°ë³¸ê°’
# =========================
st.session_state.setdefault("scenes", [])
st.session_state.setdefault("base_prompt", "")
st.session_state.setdefault("prompt_variants_text", "")

st.session_state.setdefault("image_model_label", "OpenAI gpt-image-1")
st.session_state.setdefault("image_orientation", "ì •ì‚¬ê°í˜• 1:1 (1024x1024)")
st.session_state.setdefault("image_quality", "low")

st.session_state.setdefault("video_model_label", "ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ â†’ MP4 (ë¡œì»¬ í•©ì„±)")
st.session_state.setdefault("seconds_per_scene", 3.0)
st.session_state.setdefault("video_bytes", None)
st.session_state.setdefault("video_error_msg", None)

# =========================
# ìœ í‹¸ í•¨ìˆ˜ë“¤
# =========================
def get_image_params():
    orientation = st.session_state.get("image_orientation", "ì •ì‚¬ê°í˜• 1:1 (1024x1024)")
    quality = st.session_state.get("image_quality", "low")

    if orientation.startswith("ì •ì‚¬ê°í˜•"):
        size = "1024x1024"
    elif orientation.startswith("ê°€ë¡œí˜•"):
        size = "1536x1024"
    else:
        size = "1024x1536"

    return size, quality


def generate_image(prompt: str):
    """ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ ê·¸ëŒ€ë¡œ ì´ë¯¸ì§€ ìƒì„±"""
    if not prompt:
        return None

    size, quality = get_image_params()

    image_model_label = st.session_state.get("image_model_label", "OpenAI gpt-image-1")
    model = IMAGE_MODELS.get(image_model_label, "gpt-image-1")

    resp = client.images.generate(
        model=model,
        prompt=prompt,
        size=size,
        quality=quality,
        n=1,
    )
    return resp.data[0].b64_json


def bulk_generate_images(scenes, max_workers: int = 4):
    def _task(idx):
        prompt = scenes[idx]["prompt_en"]
        b64 = generate_image(prompt)
        return idx, b64

    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futures = [ex.submit(_task, i) for i in range(len(scenes))]
        for fut in as_completed(futures):
            idx, b64 = fut.result()
            scenes[idx]["image_b64"] = b64


def b64_to_bytes(b64_str: str):
    return base64.b64decode(b64_str)


def create_video_from_scenes(
    scenes,
    seconds_per_scene: float,
    fps: int = 30,
) -> tuple[bytes | None, str | None]:
    """
    ì„±ê³µ ì‹œ (video_bytes, None)
    ì‹¤íŒ¨ ì‹œ (None, ì—ëŸ¬ë©”ì‹œì§€)
    """
    if imageio is None:
        return None, "IMAGEIO_MISSING"

    images = []
    for scene in scenes:
        if not scene.get("image_b64"):
            continue
        img_bytes = b64_to_bytes(scene["image_b64"])
        img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
        images.append(img)

    if not images:
        return None, "NO_IMAGES"

    frames_per_scene = max(1, int(seconds_per_scene * fps))
    output_path = "imageking_output.mp4"

    try:
        writer = imageio.get_writer(output_path, fps=fps)  # imageio-ffmpeg í•„ìš”
    except Exception as e:
        return None, f"WRITER_ERROR: {e}"

    try:
        for img in images:
            frame = np.asarray(img)
            for _ in range(frames_per_scene):
                writer.append_data(frame)
        writer.close()
    except Exception as e:
        return None, f"WRITE_FRAME_ERROR: {e}"

    try:
        with open(output_path, "rb") as f:
            return f.read(), None
    except Exception as e:
        return None, f"FILE_READ_ERROR: {e}"


def build_scenes_from_prompt(base_prompt: str, variants_text: str):
    """
    ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ + ë³€í˜• ë¦¬ìŠ¤íŠ¸(ì¤„ë°”ê¿ˆ)ë¡œ scenes ìƒì„±
    - ë³€í˜•ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ 1ê°œë§Œ ì‚¬ìš©
    - ë³€í˜•ì´ ì—¬ëŸ¬ ì¤„ì´ë©´ ê° ì¤„ë§ˆë‹¤ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ì— ë¶™ì—¬ì„œ í•˜ë‚˜ì˜ ì¥ë©´ìœ¼ë¡œ ì‚¬ìš©
    """
    scenes = []
    base_prompt = base_prompt.strip()

    if not base_prompt and not variants_text.strip():
        return scenes

    variant_lines = [ln.strip() for ln in variants_text.splitlines() if ln.strip()]

    # ë³€í˜•ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë§Œ 1ê°œ
    if not variant_lines:
        combined_prompt = base_prompt
        scenes.append(
            {
                "id": 1,
                "korean": base_prompt,
                "prompt_en": combined_prompt,
                "image_b64": None,
            }
        )
        return scenes

    # ë³€í˜•ì´ ìˆìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ + ê° ë³€í˜• ì¡°í•©ìœ¼ë¡œ ì—¬ëŸ¬ ì¥ë©´ ìƒì„±
    for i, v in enumerate(variant_lines, start=1):
        if base_prompt:
            combined_prompt = f"{base_prompt}, {v}"
        else:
            combined_prompt = v

        korean_block = base_prompt + ("\n" + v if base_prompt else v)

        scenes.append(
            {
                "id": i,
                "korean": korean_block,
                "prompt_en": combined_prompt,
                "image_b64": None,
            }
        )

    return scenes

# =========================
# ì‚¬ì´ë“œë°”
# =========================
with st.sidebar:
    st.markdown("### ğŸ¬ IASA")
    st.markdown("---")

    st.markdown("#### ğŸ–¼ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸")
    st.session_state["image_model_label"] = st.selectbox(
        "ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸",
        list(IMAGE_MODELS.keys()),
        index=list(IMAGE_MODELS.keys()).index(
            st.session_state.get("image_model_label", "OpenAI gpt-image-1")
        ),
    )

    # === ì´ë¯¸ì§€ ì˜µì…˜: disclosure ê·¸ë£¹ ===
    with st.expander("ğŸ–¼ ì´ë¯¸ì§€ ì˜µì…˜", expanded=True):
        st.session_state["image_orientation"] = st.radio(
            "ë¹„ìœ¨ ì„ íƒ",
            ["ì •ì‚¬ê°í˜• 1:1 (1024x1024)", "ê°€ë¡œí˜• 3:2 (1536x1024)", "ì„¸ë¡œí˜• 2:3 (1024x1536)"],
            index=["ì •ì‚¬ê°í˜• 1:1 (1024x1024)", "ê°€ë¡œí˜• 3:2 (1536x1024)", "ì„¸ë¡œí˜• 2:3 (1024x1536)"].index(
                st.session_state.get("image_orientation", "ì •ì‚¬ê°í˜• 1:1 (1024x1024)")
            ),
        )

        st.session_state["image_quality"] = st.radio(
            "í’ˆì§ˆ",
            ["low", "high"],
            index=["low", "high"].index(st.session_state.get("image_quality", "low")),
            horizontal=True,
        )

    # === ì˜ìƒ ìƒì„± ì˜µì…˜: disclosure ê·¸ë£¹ ===
    with st.expander("ğŸ¥ ì˜ìƒ ìƒì„± ì˜µì…˜", expanded=True):
        st.session_state["video_model_label"] = st.selectbox(
            "ì˜ìƒ ìƒì„± ëª¨ë¸",
            list(VIDEO_MODELS.keys()),
            index=list(VIDEO_MODELS.keys()).index(
                st.session_state.get("video_model_label", "ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ â†’ MP4 (ë¡œì»¬ í•©ì„±)")
            ),
        )

        st.session_state["seconds_per_scene"] = st.slider(
            "ì¥ë©´ë‹¹ ì˜ìƒ ê¸¸ì´ (ì´ˆ)",
            min_value=1.0,
            max_value=10.0,
            value=float(st.session_state.get("seconds_per_scene", 3.0)),
            step=0.5,
        )

# =========================
# ë©”ì¸ UI
# =========================
st.markdown(
    """
    <div>
        <div class="logo-badge">
            <span class="emoji">ğŸ¬</span>
            <span>IASA</span>
        </div>
        <div class="main-title">imageking</div>
        <div class="main-subtitle">
            í•˜ë‚˜ì˜ ê¸°ë³¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ ì •í•´ ë‘ê³ ,<br>
            ì—¬ëŸ¬ ê°€ì§€ ë³€í˜• í”„ë¡¬í”„íŠ¸ë¥¼ ì‹¤í—˜í•˜ë©´ì„œ ì›í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ì°¾ì•„ë³´ì„¸ìš”.
        </div>
    </div>
    """,
    unsafe_allow_html=True,
)

# --- ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ & ë³€í˜• ë¦¬ìŠ¤íŠ¸ ì…ë ¥ ---
base_prompt = st.text_input(
    "ê¸°ë³¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (ì˜ì–´ ê¶Œì¥)",
    value=st.session_state.get("base_prompt", ""),
    placeholder="ì˜ˆ: A Korean woman in her 20s, standing in a neon-lit street at night, 50mm lens, cinematic framing",
)

variants_text = st.text_area(
    "í”„ë¡¬í”„íŠ¸ ë³€í˜• ë¦¬ìŠ¤íŠ¸ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)",
    height=200,
    value=st.session_state.get("prompt_variants_text", ""),
    placeholder=(
        "ê° ì¤„ë§ˆë‹¤ ë‹¤ë¥¸ ë³€í˜• ìš”ì†Œë¥¼ ì ì–´ë³´ì„¸ìš”.\n"
        "ì˜ˆ)\n"
        "cinematic lighting, moody atmosphere\n"
        "sunset, orange and teal color grading\n"
        "top-down view, 35mm lens\n"
    ),
)

st.session_state["base_prompt"] = base_prompt
st.session_state["prompt_variants_text"] = variants_text

col_btn1, col_btn2 = st.columns(2)
with col_btn1:
    clicked_generate = st.button("ì´ë¯¸ì§€ ìƒì„±", type="primary", use_container_width=True)
with col_btn2:
    clicked_video = st.button("ì˜ìƒ ìƒì„±", type="secondary", use_container_width=True)

# =========================
# ì´ë¯¸ì§€ ìƒì„± ë²„íŠ¼ ë™ì‘
# =========================
if clicked_generate:
    if not base_prompt.strip() and not variants_text.strip():
        st.warning("ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë˜ëŠ” ë³€í˜• í”„ë¡¬í”„íŠ¸ë¥¼ í•˜ë‚˜ ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        scenes = build_scenes_from_prompt(base_prompt, variants_text)
        if not scenes:
            st.error("í”„ë¡¬í”„íŠ¸ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‚´ìš©ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            st.session_state["scenes"] = scenes

            with st.spinner("ì´ë¯¸ì§€ë¥¼ ë²Œí¬ë¡œ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                bulk_generate_images(st.session_state["scenes"], max_workers=4)

            st.success("âœ… í”„ë¡¬í”„íŠ¸ê°€ ì¥ë©´ìœ¼ë¡œ ë¶„ë¦¬ë˜ê³  ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.session_state["video_bytes"] = None
            st.session_state["video_error_msg"] = None

scenes = st.session_state.get("scenes", [])

# =========================
# ì˜ìƒ ìƒì„± ë²„íŠ¼ ë™ì‘
# =========================
if clicked_video:
    if not scenes or not any(s.get("image_b64") for s in scenes):
        st.warning("ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œ í›„ì— ì˜ìƒì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        if imageio is None:
            st.session_state["video_error_msg"] = (
                "`imageio` ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤. requirements.txt ì— `imageio` ì™€ `imageio-ffmpeg` ë¥¼ ì¶”ê°€í•œ ë’¤ ë‹¤ì‹œ ë°°í¬í•´ì£¼ì„¸ìš”."
            )
            st.session_state["video_bytes"] = None
        else:
            video_model_label = st.session_state.get("video_model_label", "ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ â†’ MP4 (ë¡œì»¬ í•©ì„±)")
            video_model = VIDEO_MODELS.get(video_model_label, "local_sequence_mp4")

            if video_model == "local_sequence_mp4":
                seconds_per_scene = float(st.session_state.get("seconds_per_scene", 3.0))
                with st.spinner("ì˜ìƒì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    video_bytes, err_msg = create_video_from_scenes(
                        scenes,
                        seconds_per_scene=seconds_per_scene,
                        fps=30,
                    )
                if video_bytes:
                    st.session_state["video_bytes"] = video_bytes
                    st.session_state["video_error_msg"] = None
                    st.success("ğŸ¬ ì˜ìƒì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.session_state["video_bytes"] = None
                    st.session_state["video_error_msg"] = (
                        "ì˜ìƒ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"
                        "ëŒ€ë¶€ë¶„ì€ `imageio-ffmpeg` ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ffmpeg í”ŒëŸ¬ê·¸ì¸ì„ ì°¾ì§€ ëª»í•´ì„œ ìƒê¸°ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.\n"
                        "requirements.txt ì— `imageio-ffmpeg` ë¥¼ ì¶”ê°€í•˜ê³  ë‹¤ì‹œ ë°°í¬í•´ ì£¼ì„¸ìš”.\n\n"
                        f"ë‚´ë¶€ ì˜¤ë¥˜ ë©”ì‹œì§€: {err_msg}"
                    )
            else:
                st.session_state["video_error_msg"] = "ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì€ ì˜ìƒ ìƒì„± ëª¨ë¸ì…ë‹ˆë‹¤."
                st.session_state["video_bytes"] = None

# ==========================
# ê²°ê³¼ í…Œì´ë¸” (ìŠ¤í¬ë¡¤ ì»¨í…Œì´ë„ˆ)
# =========================
if scenes:
    st.subheader("í”„ë¡¬í”„íŠ¸ ë³€í˜•ë³„ ì´ë¯¸ì§€ ê²°ê³¼")

    with st.container():
        st.markdown('<div class="results-container">', unsafe_allow_html=True)

        header_cols = st.columns([0.5, 2, 2, 1, 0.9])
        header_cols[0].markdown("**ë²ˆí˜¸**")
        header_cols[1].markdown("**ê¸°ë³¸ + ë³€í˜• í”„ë¡¬í”„íŠ¸**")
        header_cols[2].markdown("**ìµœì¢… ì „ë‹¬ í”„ë¡¬í”„íŠ¸**")
        header_cols[3].markdown("**ì´ë¯¸ì§€**")
        header_cols[4].markdown("**ì¡°ì‘**")

        st.markdown("---")

        for i, scene in enumerate(scenes):
            cols = st.columns([0.5, 2, 2, 1, 0.9])

            cols[0].write(scene["id"])

            korean_html = scene["korean"].replace("\n", "<br>")
            cols[1].markdown(
                f'<div class="small-text-cell">{korean_html}</div>',
                unsafe_allow_html=True,
            )

            prompt_html = scene["prompt_en"].replace("\n", "<br>")
            cols[2].markdown(
                f'<div class="small-text-cell">{prompt_html}</div>',
                unsafe_allow_html=True,
            )

            if scene["image_b64"]:
                img_bytes = b64_to_bytes(scene["image_b64"])
                cols[3].image(img_bytes, use_column_width=True)
            else:
                cols[3].write("ì•„ì§ ì´ë¯¸ì§€ ì—†ìŒ")

            if cols[4].button("ì¬ ìƒì„±", key=f"regen_{scene['id']}"):
                with st.spinner(f"{scene['id']}ë²ˆ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ìƒì„± ì¤‘..."):
                    new_b64 = generate_image(scene["prompt_en"])
                    st.session_state["scenes"][i]["image_b64"] = new_b64
                st.rerun()

        st.markdown("</div>", unsafe_allow_html=True)
else:
    st.info("ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ì™€ ë³€í˜• í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ê³  **ì´ë¯¸ì§€ ìƒì„±** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

# =========================
# ìƒì„±ëœ ì˜ìƒ / ì˜¤ë¥˜ í‘œì‹œ
# =========================
if st.session_state.get("video_bytes"):
    st.subheader("ğŸ¬ ìƒì„±ëœ ì˜ìƒ ë¯¸ë¦¬ë³´ê¸°")
    st.video(st.session_state["video_bytes"])

    st.download_button(
        label="ğŸ“¥ ì˜ìƒ ë‹¤ìš´ë¡œë“œ (MP4)",
        data=st.session_state["video_bytes"],
        file_name="imageking_output.mp4",
        mime="video/mp4",
    )
elif st.session_state.get("video_error_msg"):
    st.subheader("âš ï¸ ì˜ìƒ ìƒì„± ì˜¤ë¥˜")
    st.error(st.session_state["video_error_msg"])
